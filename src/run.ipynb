{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timm\n",
    "\n",
    "We use timm model architectures and create a wrapper class for adding a classification head and extracting embeddings.\n",
    "\n",
    "Note: [run.py](https://github.com/dwiepert/mayo-timm/blob/main/src/run.py) script can also do evaluation only. \n",
    "\n",
    "Authors: Daniela Wiepert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment must include the following packages, all of which can be dowloaded with pip or conda:\n",
    "* albumentations\n",
    "* librosa\n",
    "* torch, torchvision, torchaudio\n",
    "* tqdm (this is essentially enumerate(dataloader) except it prints out a nice progress bar for you)\n",
    "* speechbrain \n",
    "* pyarrow\n",
    "* timm\n",
    "\n",
    "If running on your local machine and not in a GCP environment, you will also need to install:\n",
    "* google-cloud-storage\n",
    "\n",
    "The [requirements.txt](https://github.com/dwiepert/mayo-ecapa-tdnn/blob/main/requirements.txt) can be used to set up this environment. \n",
    "\n",
    "To access data stored in GCS on your local machine, you will need to additionally run\n",
    "\n",
    "```gcloud auth application-default login```\n",
    "\n",
    "```gcloud auth application-defaul set-quota-project PROJECT_NAME```\n",
    "\n",
    "Please note that if using GCS, the model expects arguments like model paths or directories to start with `gs://BUCKET_NAME/...` with the exception of defining an output cloud directory which should just be the prefix to save within a bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "#built-in\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#third-party\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "from google.cloud import storage\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "#local\n",
    "from utilities import *\n",
    "from models import *\n",
    "from dataloader import AudioDataset\n",
    "from loops import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload/Download functions & Data loading functions\n",
    "These are defined in `utilities/load_utils.py`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "There are many mutable arguments when running. Please explore the different options and make sure all arguments are set as you would like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#Inputs\n",
    "parser.add_argument('-i','--prefix',default='speech_ai/speech_lake/', help='Input directory or location in google cloud storage bucket containing files to load')\n",
    "parser.add_argument(\"-s\", \"--study\", choices = ['r01_prelim','speech_poc_freeze_1', None], default='speech_poc_freeze_1', help=\"specify study name\")\n",
    "parser.add_argument(\"-d\", \"--data_split_root\", default='gs://ml-e107-phi-shared-aif-us-p/speech_ai/share/data_splits/amr_subject_dedup_594_train_100_test_binarized_v20220620/test.csv', help=\"specify file path where datasplit is located. If you give a full file path to classification, an error will be thrown. On the other hand, evaluation and embedding expects a single .csv file.\")\n",
    "parser.add_argument('-l','--label_txt', default='src/labels.txt')\n",
    "parser.add_argument('--lib', default=False, type=bool, help=\"Specify whether to load using librosa as compared to torch audio\")\n",
    "parser.add_argument(\"--trained_mdl_path\", default=None, help=\"specify path to trained model\")\n",
    "parser.add_argument(\"--model_type\", default='efficientnet_b0', help='specify the timm model type to initialize')\n",
    "#GCS\n",
    "parser.add_argument('-b','--bucket_name', default='ml-e107-phi-shared-aif-us-p', help=\"google cloud storage bucket name\")\n",
    "parser.add_argument('-p','--project_name', default='ml-mps-aif-afdgpet01-p-6827', help='google cloud platform project name')\n",
    "parser.add_argument('--cloud', default=False, type=bool, help=\"Specify whether to save everything to cloud\")\n",
    "#output\n",
    "parser.add_argument(\"--dataset\", default=None,type=str, help=\"When saving, the dataset arg is used to set file names. If you do not specify, it will assume the lowest directory from data_split_root\")\n",
    "parser.add_argument(\"-o\", \"--exp_dir\", default='./experiments', help='specify LOCAL output directory')\n",
    "parser.add_argument('--cloud_dir', default='', type=str, help=\"if saving to the cloud, you can specify a specific place to save to in the CLOUD bucket\")\n",
    "#Mode specific\n",
    "parser.add_argument(\"-m\", \"--mode\", choices=['train','eval','extraction'], default='train')\n",
    "parser.add_argument('--embedding_type', type=str, default='ft', help='specify whether embeddings should be extracted from classification head (ft) or base pretrained model (pt)', choices=['ft','pt'])\n",
    "#Audio configuration parameters\n",
    "parser.add_argument(\"--dataset_mean\", default=-4.2677393, type=float, help=\"the dataset mean, used for input normalization\")\n",
    "parser.add_argument(\"--dataset_std\", default=4.5689974, type=float, help=\"the dataset std, used for input normalization\")\n",
    "parser.add_argument(\"--target_length\", default=1024, type=int, help=\"the input length in frames\")\n",
    "parser.add_argument(\"--num_mel_bins\", default=128,type=int, help=\"number of input mel bins\")\n",
    "parser.add_argument(\"--resample_rate\", default=16000,type=int, help='resample rate for audio files')\n",
    "parser.add_argument(\"--reduce\", default=True, type=bool, help=\"Specify whether to reduce to monochannel\")\n",
    "parser.add_argument(\"--clip_length\", default=10.0, type=int, help=\"If truncating audio, specify clip length in seconds. 0 = no truncation\")\n",
    "parser.add_argument(\"--tshift\", default=0, type=float, help=\"Specify p for time shift transformation\")\n",
    "parser.add_argument(\"--speed\", default=0, type=float, help=\"Specify p for speed tuning\")\n",
    "parser.add_argument(\"--gauss\", default=0, type=float, help=\"Specify p for adding gaussian noise\")\n",
    "parser.add_argument(\"--pshift\", default=0, type=float, help=\"Specify p for pitch shifting\")\n",
    "parser.add_argument(\"--pshiftn\", default=0, type=float, help=\"Specify number of steps for pitch shifting\")\n",
    "parser.add_argument(\"--gain\", default=0, type=float, help=\"Specify p for gain\")\n",
    "parser.add_argument(\"--stretch\", default=0, type=float, help=\"Specify p for audio stretching\")\n",
    "parser.add_argument('--freqm', help='frequency mask max length', type=int, default=0)\n",
    "parser.add_argument('--timem', help='time mask max length', type=int, default=0)\n",
    "parser.add_argument(\"--mixup\", type=float, default=0, help=\"how many (0-1) samples need to be mixup during training\")\n",
    "parser.add_argument(\"--noise\", type=bool, default=False, help=\"specify if augment noise in finetuning\")\n",
    "parser.add_argument(\"--skip_norm\", type=bool, default=False, help=\"specify whether to skip normalization on spectrogram\")\n",
    "#Model parameters\n",
    "parser.add_argument(\"-bs\", \"--batch_size\", type=int, default=8, help=\"specify batch size\")\n",
    "parser.add_argument(\"-nw\", \"--num_workers\", type=int, default=0, help=\"specify number of parallel jobs to run for data loader\")\n",
    "parser.add_argument(\"-lr\", \"--learning_rate\", type=float, default=0.0003, help=\"specify learning rate\")\n",
    "parser.add_argument(\"-e\", \"--epochs\", type=int, default=1, help=\"specify number of training epochs\")\n",
    "parser.add_argument(\"--optim\", type=str, default=\"adam\", help=\"training optimizer\", choices=[\"adam\", \"adamw\"])\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=.0001, help='specify weight decay for adamw')\n",
    "parser.add_argument(\"--loss\", type=str, default=\"BCE\", help=\"the loss function for finetuning, depend on the task\", choices=[\"MSE\", \"BCE\"])\n",
    "parser.add_argument(\"--scheduler\", type=str, default=\"onecycle\", help=\"specify lr scheduler\", choices=[\"onecycle\", None])\n",
    "parser.add_argument(\"--max_lr\", type=float, default=0.01, help=\"specify max lr for lr scheduler\")\n",
    "#classification head parameters\n",
    "parser.add_argument(\"--activation\", type=str, default='relu', help=\"specify activation function to use for classification head\")\n",
    "parser.add_argument(\"--final_dropout\", type=float, default=0.3, help=\"specify dropout probability for final dropout layer in classification head\")\n",
    "parser.add_argument(\"--layernorm\", type=bool, default=False, help=\"specify whether to include the LayerNorm in classification head\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment\n",
    "The first step is to make sure the GCS bucket is initialized if given a `bucket_name`. Additionally, the list of target labels must be set. There are a few other arguments to consider as well\n",
    "\n",
    "In the original implementation, the list must be given as a `.txt` file to pass through the command line. In this implementation, we will set it as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Torch version: ',torch.__version__)\n",
    "print('Cuda availability: ', torch.cuda.is_available())\n",
    "print('Cuda version: ', torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "# (1) Set up GCS\n",
    "if args.bucket_name is not None:\n",
    "    storage_client = storage.Client(project=args.project_name)\n",
    "    bucket = storage_client.bucket(args.bucket_name)\n",
    "else:\n",
    "    bucket = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2), check if given study or if the prefix is the full prefix.\n",
    "if args.study is not None:\n",
    "    args.prefix = os.path.join(args.prefix, args.study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) get dataset name\n",
    "if args.dataset is None:\n",
    "    if args.trained_mdl_path is None or args.mode == 'train':\n",
    "        if '.csv' in args.data_split_root:\n",
    "            args.dataset = '{}_{}'.format(os.path.basename(os.path.dirname(args.data_split_root)), os.path.basename(args.data_split_root[:-4]))\n",
    "        else:\n",
    "            args.dataset = os.path.basename(args.data_split_root)\n",
    "    else:\n",
    "        args.dataset = os.path.basename(args.trained_mdl_path)[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) get target labels\n",
    "    #get list of target labels\n",
    "args.target_labels = ['slow rate',\n",
    "                        'irregular artic breakdowns',\n",
    "                        'rapid rate',\n",
    "                        'distortions',\n",
    "                        'strained']\n",
    "\n",
    "args.n_class = len(args.target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (5) check if output directory exists, SHOULD NOT BE A GS:// path\n",
    "if not os.path.exists(args.exp_dir):\n",
    "    os.makedirs(args.exp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) check that clip length has been set\n",
    "if args.clip_length == 0:\n",
    "    try: \n",
    "        assert args.batch_size == 1, 'Not currently compatible with different length wav files unless batch size has been set to 1'\n",
    "    except:\n",
    "        args.batch_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) dump arguments\n",
    "args_path = \"%s/args.pkl\" % args.exp_dir\n",
    "with open(args_path, \"wb\") as f:\n",
    "    pickle.dump(args, f)\n",
    "#in case of error, everything is immediately uploaded to the bucket\n",
    "if args.cloud:\n",
    "    upload(args.cloud_dir, args_path, bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) check if trained model is stored in gcs bucket or confirm it exists on local machine\n",
    "if args.trained_mdl_path is not None:\n",
    "    args.trained_mdl_path = gcs_model_exists(args.trained_mdl_path, args.bucket_name, args.exp_dir, bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #(9) add bucket to args\n",
    "args.bucket = bucket"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will start with the training option and not include the option for only evaluating an already trained model (which is available in the full .py script)\n",
    "\n",
    "When loading data, we start with a data split root, which we expect to be a directory containing a `train.csv` file and `test.csv` file with file names for train/test and the associated label data.\n",
    "\n",
    "We load the data, set up an audio configuration, set up `AudioDataset` objects (from `dataloader.py`), and set up the dataloaders.\n",
    "\n",
    "The transforms in `AudioDataset` are set up using functions from `utilities/speech_utils.py`. \n",
    "\n",
    "The dataloaders take in the datasets and batch size + number of workers.\n",
    "\n",
    "Please note that the resulting samples will be a dictionary with the keys `uid`, `waveform`, `targets`, `sample_rate`, `fbank`.\n",
    "\n",
    "We randomly sample the train.csv within the load_data function to get a validation dataset of 50 samples. See `load_utils.py` for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running training: ')\n",
    "# (1) load data\n",
    "assert '.csv' not in args.data_split_root, f'May have given a full file path, please confirm this is a directory: {args.data_split_root}'\n",
    "train_df, val_df, test_df = load_data(args.data_split_root, args.target_labels, args.exp_dir, args.cloud, args.cloud_dir, args.bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) set audio configurations (val loader and eval loader will both use the eval_audio_conf\n",
    "train_audio_conf = {'dataset': args.dataset, 'mode': 'train', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n",
    "\n",
    "#note, mixup should always be 0 for the evaluation\n",
    "eval_audio_conf = {'dataset': args.dataset, 'mode': 'evaluation', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': 0, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #(3) Generate audio dataset, note that if bucket not given, it assumes None and loads from local files\n",
    "train_dataset = AudioDataset(annotations_df=train_df, target_labels=args.target_labels, audio_conf=train_audio_conf, \n",
    "                                prefix=args.prefix, bucket=args.bucket, librosa=args.lib) #librosa = True (might need to debug this one)\n",
    "val_dataset = AudioDataset(annotations_df=val_df, target_labels=args.target_labels, audio_conf=eval_audio_conf, \n",
    "                                prefix=args.prefix, bucket=args.bucket, librosa=args.lib) #librosa = True (might need to debug this one)\n",
    "eval_dataset = AudioDataset(annotations_df=test_df, target_labels=args.target_labels, audio_conf=eval_audio_conf, \n",
    "                            prefix=args.prefix, bucket=args.bucket, librosa=args.lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(4) set up data loaders (val loader always has batchsize 1)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_fn)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: TEST WHETHER YOU CAN LOAD A BATCH\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model\n",
    "\n",
    "Set up the model using classes from `timm_models.py`. This includes a wrapper for a speech classification model that adds on a classification head with a dense layer, ReLU, dropout, and a final linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (4) initialize model\n",
    "model = timmForSpeechClassification(args.model_type, args.n_class, args.activation, args.final_dropout, args.layernorm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training, evaluation\n",
    "\n",
    "The model training loops are originally implemented in `loops.py`, but we will include them here for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, dataloader_val):\n",
    "    '''\n",
    "    Validation loop for training\n",
    "    :param model: model\n",
    "    :param criterion: loss function\n",
    "    :param dataloader_val: dataloader object with validation data\n",
    "    :return validation_loss: list with validation loss for each batch\n",
    "    '''\n",
    "    validation_loss = list()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        model = model.cuda()\n",
    "    except:\n",
    "        model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader_val):\n",
    "            x = torch.unsqueeze(batch['fbank'],1)\n",
    "            targets = batch['targets']\n",
    "            try:\n",
    "                x,targets = x.cuda(), targets.cuda()\n",
    "            except:\n",
    "                x, targets = x.to(device), targets.to(device)\n",
    "            o = model(x)\n",
    "            val_loss = criterion(o, targets)\n",
    "            validation_loss.append(val_loss.item())\n",
    "\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader_train, dataloader_val = None, \n",
    "             optim='adamw', learning_rate=0.001, weight_decay=0.001, \n",
    "             loss_fn='BCE', sched='onecycle', max_lr=0.01,\n",
    "             epochs=10, exp_dir='', cloud=False, cloud_dir='', bucket=None):\n",
    "    \"\"\"\n",
    "    Training loop for training\n",
    "    :param model: model\n",
    "    :param dataloader_train: dataloader object with training data\n",
    "    :param dataloader_val: dataloader object with validation data\n",
    "    :param optim: type of optimizer to initialize\n",
    "    :param learning_rate: optimizer learning rate\n",
    "    :param weight_decay: weight decay value for adamw optimizer\n",
    "    :param loss_fn: type of loss function to initialize\n",
    "    :param sched: type of scheduler to initialize\n",
    "    :param max_lr: max learning rate for onecycle scheduler\n",
    "    :param epochs: number of epochs to run pretraining\n",
    "    :param exp_dir: output directory on local machine\n",
    "    :param cloud: boolean indicating whether uploading to cloud\n",
    "    :param cloud_dir: output directory in google cloud storage bucket\n",
    "    :param bucket: initialized GCS bucket object\n",
    "    :return model: finetuned model\n",
    "    \"\"\"\n",
    "    print('Finetuning start')\n",
    "    #send to gpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    try:\n",
    "        model = model.cuda()\n",
    "    except:\n",
    "        model = model.to(device)\n",
    "\n",
    "    #loss\n",
    "    if loss_fn == 'MSE':\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    elif loss_fn == 'BCE':\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        raise ValueError(f'Given loss function ({loss_fn}) not supported. Must be either MSE or BCE')\n",
    "    #optimizer\n",
    "    if optim == 'adam':\n",
    "        optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad],lr=learning_rate)\n",
    "    elif optim == 'adamw':\n",
    "         optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f'Given optimizer ({optim}) not supported. Must be either adam or adamw')\n",
    "    \n",
    "    if sched == 'onecycle':\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(dataloader_train), epochs=epochs)\n",
    "    else:\n",
    "        scheduler = None\n",
    "    \n",
    "    #train\n",
    "    for e in range(epochs):\n",
    "        training_loss = list()\n",
    "        #t0 = time.time()\n",
    "        model.train()\n",
    "        for batch in tqdm(dataloader_train):\n",
    "            x = torch.unsqueeze(batch['fbank'],1)\n",
    "            targets = batch['targets']\n",
    "            try:\n",
    "                x = x.cuda()\n",
    "                targets = targets.cuda()\n",
    "            except:\n",
    "                x, targets = x.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            o = model(x)\n",
    "            loss = criterion(o, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            loss_item = loss.item()\n",
    "            training_loss.append(loss_item)\n",
    "\n",
    "        if e % 10 == 0:\n",
    "            #SET UP LOGS\n",
    "            if scheduler is not None:\n",
    "                lr = scheduler.get_last_lr()\n",
    "            else:\n",
    "                lr = learning_rate\n",
    "            logs = {'epoch': e, 'optim':optim, 'loss_fn': loss_fn, 'lr': lr, 'scheduler':sched}\n",
    "    \n",
    "            logs['training_loss_list'] = training_loss\n",
    "            training_loss = np.array(training_loss)\n",
    "            logs['running_loss'] = np.sum(training_loss)\n",
    "            logs['training_loss'] = np.mean(training_loss)\n",
    "\n",
    "            print('RUNNING LOSS', e, np.sum(training_loss) )\n",
    "            print(f'Training loss: {np.mean(training_loss)}')\n",
    "\n",
    "            if dataloader_val is not None:\n",
    "                print(\"Validation start\")\n",
    "                validation_loss = validation(model, criterion, dataloader_val)\n",
    "\n",
    "                logs['val_loss_list'] = validation_loss\n",
    "                validation_loss = np.array(validation_loss)\n",
    "                logs['val_running_loss'] = np.sum(validation_loss)\n",
    "                logs['val_loss'] = np.mean(validation_loss)\n",
    "                \n",
    "                print('RUNNING VALIDATION LOSS',e, np.sum(validation_loss) )\n",
    "                print(f'Validation loss: {np.mean(validation_loss)}')\n",
    "            \n",
    "            #SAVE LOGS\n",
    "            json_string = json.dumps(logs)\n",
    "            logs_path = os.path.join(exp_dir, 'logs_ft_epoch{}.json'.format(e))\n",
    "            with open(logs_path, 'w') as outfile:\n",
    "                json.dump(json_string, outfile)\n",
    "            \n",
    "            #SAVE CURRENT MODEL\n",
    "            print(f'Saving epoch {e}')\n",
    "            mdl_path = os.path.join(exp_dir, 'timm_ft_mdl_epoch{}.pt'.format(e))\n",
    "            torch.save(model.state_dict(), mdl_path)\n",
    "            \n",
    "            optim_path = os.path.join(exp_dir, 'timm_ft_optim_epoch{}.pt'.format(e))\n",
    "            torch.save(optimizer.state_dict(), optim_path)\n",
    "\n",
    "            if cloud:\n",
    "                upload(cloud_dir, logs_path, bucket)\n",
    "                upload(cloud_dir, mdl_path, bucket)\n",
    "                upload(cloud_dir, optim_path, bucket)\n",
    "\n",
    "    print('Finetuning finished')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, dataloader_eval):\n",
    "    \"\"\"\n",
    "    Start model evaluation\n",
    "    :param model: model\n",
    "    :param dataloader_eval: dataloader object with evaluation data\n",
    "    :return preds: model predictions\n",
    "    :return targets: model targets (actual values)\n",
    "    \"\"\"\n",
    "    print('Evaluation start')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    outputs = []\n",
    "    t = []\n",
    "    try:\n",
    "        model = model.cuda()\n",
    "    except:\n",
    "        model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader_eval):\n",
    "            x = torch.unsqueeze(batch['fbank'],1)\n",
    "            targets = batch['targets']\n",
    "            try:\n",
    "                x,targets = x.cuda(), targets.cuda()\n",
    "            except:\n",
    "                x, targets = x.to(device), targets.to(device)\n",
    "            o = model(x)\n",
    "            outputs.append(o)\n",
    "            t.append(targets)\n",
    "\n",
    "    outputs = torch.cat(outputs).cpu().detach()\n",
    "    t = torch.cat(t).cpu().detach()\n",
    "    # SAVE PREDICTIONS AND TARGETS \n",
    "    print('Evaluation finished')\n",
    "    return outputs, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) run model\n",
    "model = train(model, train_loader, val_loader, \n",
    "                args.optim, args.learning_rate, args.weight_decay,\n",
    "                args.loss, args.scheduler, args.max_lr, args.epochs,\n",
    "                args.exp_dir, args.cloud, args.cloud_dir, args.bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "print('Saving final model')\n",
    "mdl_path = os.path.join(args.exp_dir, '{}_{}_{}_epoch{}_{}_mdl.pt'.format(args.dataset, args.n_class, args.optim, args.epochs, args.model_type))\n",
    "torch.save(model.state_dict(), mdl_path)\n",
    "\n",
    "if args.cloud:\n",
    "    upload(args.cloud_dir, mdl_path, args.bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # (6) start evaluating\n",
    "preds, targets = evaluation(model, eval_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving predictions and targets')\n",
    "pred_path = os.path.join(args.exp_dir, '{}_{}_{}_epoch{}_{}_predictions.pt'.format(args.dataset, args.n_class, args.optim, args.epochs, args.model_type))\n",
    "target_path = os.path.join(args.exp_dir, '{}_{}_{}_epoch{}_{}_targets.pt'.format(args.dataset, args.n_class, args.optim, args.epochs, args.model_type))\n",
    "torch.save(preds, pred_path)\n",
    "torch.save(targets, target_path)\n",
    "\n",
    "if args.cloud:\n",
    "    upload(args.cloud_dir, pred_path, args.bucket)\n",
    "    upload(args.cloud_dir, target_path, args.bucket)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embeddings\n",
    "\n",
    "Embedding extraction is a slightly different process. We instead load in one csv file, initialize and load a trained model, then run the embedding loop which extracts the emebdding from the output of the base model if specifiedd as 'pt' or the output of the first layer of the classification head 'ft'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_split_root = 'gs://ml-e107-phi-shared-aif-us-p/speech_ai/share/data_splits/amr_subject_dedup_594_train_100_test_binarized_v20220620/test.csv'\n",
    "args.embedding_type='ft' #if 'pt', it will get embeddings from only the pretrained model, 'wt' from weighted sum parameter\n",
    "#args.trained_mdl_path = None #TODO: must set to a finetuned model if you want it to load and get embeddings in that way.\n",
    "args.target_labels = [] #not a required step, but embeddings do not require target labels to run. \n",
    "args.n_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Embedding Extraction: ')\n",
    "assert args.trained_mdl_path is not None, 'must give a model to load for embedding extraction. '\n",
    "# Get original \n",
    "model_args = load_args(args, args.trained_mdl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) load data to get embeddings for\n",
    "assert '.csv' in args.data_split_root, f'A csv file is necessary for embedding extraction. Please make sure this is a full file path: {args.data_split_root}'\n",
    "annotations_df = pd.read_csv(args.data_split_root, index_col = 'uid') #data_split_root should use the CURRENT arguments regardless of the finetuned model\n",
    "\n",
    "if 'distortions' in args.target_labels and 'distortions' not in annotations_df.columns:\n",
    "    annotations_df[\"distortions\"]=((annotations_df[\"distorted Cs\"]+annotations_df[\"distorted V\"])>0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) set audio configurations\n",
    "args.mixup=0 #mixup should always be 0 for embedding extraction\n",
    "audio_conf = {'dataset': args.dataset, 'mode': 'evaluation', 'resample_rate': args.resample_rate, 'reduce': args.reduce, 'clip_length': args.clip_length,\n",
    "                'tshift':args.tshift, 'speed':args.speed, 'gauss_noise':args.gauss, 'pshift':args.pshift, 'pshiftn':args.pshiftn, 'gain':args.gain, 'stretch': args.stretch,\n",
    "                'num_mel_bins': args.num_mel_bins, 'target_length': args.target_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'noise':args.noise,\n",
    "                'mean':args.dataset_mean, 'std':args.dataset_std, 'skip_norm':args.skip_norm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) set up dataloader with current args\n",
    "dataset = AudioDataset(annotations_df=annotations_df, target_labels=args.target_labels, audio_conf=audio_conf, \n",
    "                            prefix=args.prefix, bucket=args.bucket, librosa=args.lib)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True, collate_fn=collate_fn) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) initialize model\n",
    "model = timmForSpeechClassification(model_args.model_type, model_args.n_class, model_args.activation, model_args.final_dropout, model_args.layernorm)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sd = torch.load(args.trained_mdl_path, map_location=device)\n",
    "model.load_state_dict(sd, strict=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the embedding extraction loop is implemented in `loops.py`, but we will include it here for context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_extraction(model, dataloader, embedding_type='ft'):\n",
    "    \"\"\"\n",
    "    Run a specific subtype of evaluation for getting embeddings.\n",
    "    :param model: model\n",
    "    :param dataloader_eval: dataloader object with data to get embeddings for\n",
    "    :param embedding_type: string specifying whether embeddings should be extracted from classification head (ft) or base pretrained model (pt)\n",
    "    :param layer: int indicating which hidden state layer to use.\n",
    "    :param task: finetuning task, only used for 'pt' or 'wt' embedding extraction.\n",
    "    :return embeddings: an np array containing the embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    print('Calculating Embeddings')\n",
    "    embeddings = np.array([])\n",
    "    # send to gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    try: \n",
    "        model = model.cuda()\n",
    "    except:\n",
    "        model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch in tqdm(dataloader):\n",
    "            x = torch.unsqueeze(batch['fbank'],1)\n",
    "            try:\n",
    "                x = x.cuda()\n",
    "            except:\n",
    "                x = x.to(device)\n",
    "            e = model.extract_embedding(x, embedding_type)\n",
    "            if embeddings.size == 0:\n",
    "                embeddings = e\n",
    "            else:\n",
    "                embeddings = np.append(embeddings, e, axis=0)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def calc_auc(preds, targets, target_labels,\n",
    "         exp_dir, cloud, cloud_dir, bucket):\n",
    "    \"\"\"\n",
    "    Get AUC scores, doesn't return, just saves the metrics to a csv\n",
    "    :param args: dict with all the argument values\n",
    "    :param preds: model predictions\n",
    "    :param targets: model targets (actual values)\n",
    "    \"\"\"\n",
    "    #get AUC score and all data for ROC curve\n",
    "    preds = preds[targets.isnan().sum(1)==0]\n",
    "    targets[targets.isnan().sum(1)==0]\n",
    "    pred_mat=torch.sigmoid(preds).numpy()\n",
    "    target_mat=targets.numpy()\n",
    "    aucs=roc_auc_score(target_mat, pred_mat, average = None) #TODO: this doesn't work when there is an array with all labels as 0???\n",
    "    print(aucs)\n",
    "    data = pd.DataFrame({'Label':target_labels, 'AUC':aucs})\n",
    "    data.to_csv(os.path.join(exp_dir, 'aucs.csv'), index=False)\n",
    "    if cloud:\n",
    "        upload(cloud_dir, os.path.join(exp_dir, 'aucs.csv'), bucket)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) get embeddings\n",
    "embeddings = embedding_extraction(model, loader, args.embedding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embed = pd.DataFrame([[r] for r in embeddings], columns = ['embedding'], index=annotations_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pqt_path = '{}/{}_{}_embeddings.pqt'.format(args.exp_dir, args.dataset, args.embedding_type)\n",
    "    \n",
    "    df_embed.to_parquet(path=pqt_path, index=True, engine='pyarrow') \n",
    "\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, pqt_path, args.bucket)\n",
    "except:\n",
    "    print('Unable to save as pqt, saving instead as csv')\n",
    "    csv_path = '{}/{}_{}_embeddings.csv'.format(args.exp_dir, args.dataset, args.embedding_type)\n",
    "    df_embed.to_csv(csv_path, index=True)\n",
    "\n",
    "    if args.cloud:\n",
    "        upload(args.cloud_dir, csv_path, args.bucket)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
